# wiki-text-nlp-classification
This repository contains a text classification project focused on Wikipedia articles. Using Natural Language Processing (NLP) techniques, the project classifies articles into distinct categories, emphasizing geographical and non-geographical content. The classification is powered by a Naive Bayes model trained on a diverse set of Wikipedia articles. Explore, contribute, and enhance the capabilities of this NLP-driven classification system.
  Key Features:

Text classification using NLP
Distinct categories: geographical and non-geographical
Naive Bayes machine learning model
Wikipedia article dataset
    Operational Structure:

Data Collection:

Fetch Wikipedia articles using the Wikipedia API.
Pre-processing:

Tokenization, lowercasing, and stopwords removal.
Feature Extraction:

Utilize TF-IDF vectorizer for feature extraction.
Model Training:

Train a Naive Bayes machine learning model.
Classification:

Classify new Wikipedia articles into geographical or non-geographical categories.
    Technology Stack:

Python:

The project is implemented using Python, leveraging its rich ecosystem of libraries for NLP and machine learning.
Scikit-learn:

Scikit-learn is utilized for machine learning tasks, providing efficient tools for data processing and model training.
NLTK:

The Natural Language Toolkit (NLTK) aids in tokenization and stopwords removal during pre-processing.
